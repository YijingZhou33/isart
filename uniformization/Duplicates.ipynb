{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_word_synonyms_from_sent(word, sent):\n",
    "    word_synonyms = []\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemma_names():\n",
    "#             if lemma in sent and lemma != word:\n",
    "            if lemma in sent:\n",
    "                word_synonyms.append(lemma)\n",
    "    return word_synonyms\n",
    "\n",
    "word = \"patient\"\n",
    "sent = \"incorrect patient in the room\".split( )\n",
    "word_synonyms = set(get_word_synonyms_from_sent(word, sent))\n",
    "print (\"WORD:\", word)\n",
    "print (\"SENTENCE:\", sent)\n",
    "print (\"SYNONYMS FOR '\" + word.upper() + \"' FOUND IN THE SENTENCE: \" + \", \".join(word_synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 = \"At first fraction wrong patient\".lower().split( )\n",
    "\n",
    "fm2 = \"Incorrect patient in the room\".lower().split( )\n",
    "\n",
    "def get_word_synonyms_from_sent(fm1, fm2):\n",
    "    word_synonyms = []\n",
    "    for word in fm1:\n",
    "        for synset in wordnet.synsets(word):\n",
    "            for lemma in synset.lemma_names():\n",
    "                if lemma in fm2:\n",
    "                    word_synonyms.append(lemma)\n",
    "    return word_synonyms\n",
    "\n",
    "word_synonyms = set(get_word_synonyms_from_sent(fm1, fm2))\n",
    "\n",
    "print (\"SYNONYMS FOR '\" + \" \".join(fm1) + \"' FOUND IN \" + \" \".join(fm2) + \": \" + \", \".join(word_synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c558ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"misinterpretation\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "\n",
    "print(set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a37025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db09eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from word_forms.word_forms import get_word_forms\n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c3dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data'\n",
    "input_file = 'iSART process map V3.xlsx'\n",
    "output_file_separate = 'duplicates_separate.xlsx'\n",
    "output_file = 'duplicates.xlsx'\n",
    "sheet_name = 'FMs_count'\n",
    "rows = 585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490bedc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_path = os.path.join(folder, input_file)\n",
    "output_separate_path = os.path.join(folder, output_file_separate)\n",
    "output_path = os.path.join(folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0653b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.DataFrame(pd.read_excel(input_path, sheet_name, nrows=rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3017d75",
   "metadata": {},
   "source": [
    "### Extract subprocess id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9357076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel['subprocess_id'] = df_excel['Subprocess'].str.strip().str.split('.').str[0]\n",
    "df_excel.loc[df_excel['subprocess_id'].str.contains('A', na=False), 'subprocess_id'] = -1 # A.\n",
    "df_excel['subprocess_id'] = df_excel['subprocess_id'].fillna(0) # unknown "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7a4c5",
   "metadata": {},
   "source": [
    "### Extract step id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804cb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel['step_id'] = df_excel['Step'].str.strip().str.split(' ').str[0].str.split('.').str[1]\n",
    "df_excel.loc[df_excel['step_id'].str.contains('A', na=False), 'step_id'] = -1 # A\n",
    "df_excel.loc[df_excel['step_id'].str.contains('\\?', na=False), 'step_id'] = 0 # unknown\n",
    "df_excel['step_id'] = df_excel['step_id'].fillna(0) # unknown "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84880a8",
   "metadata": {},
   "source": [
    "### Generate process id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d038497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel['process_id'] = df_excel.\\\n",
    "apply(lambda r: (r['subprocess_id'] + '-' + r['step_id']) if r['subprocess_id'] != -1 and r['subprocess_id'] != 0 and r['step_id'] != 0 and r['step_id'] != -1 else np.NaN, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b90091",
   "metadata": {},
   "source": [
    "## Find duplicates based on keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333406ed",
   "metadata": {},
   "source": [
    "### Group dataframes by process_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "594a79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_dict = {k: df for k, df in df_excel.groupby('process_id')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77414cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list = [\n",
    "    {\n",
    "        'process_id': '6-4', \n",
    "        'keywords': [\n",
    "            'Wrong, incorrect, poor, imperfect', \n",
    "            'Contouring, delineation, outline, exams, PTV, CTV, GTV, target, organs at risk'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'process_id': '6-5', \n",
    "        'keywords': [\n",
    "            'Wrong, incorrect', \n",
    "            'Prescription'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'process_id': '8-1', \n",
    "        'keywords': [\n",
    "            'Wrong, mistaken, incorrect,  lack, missed', \n",
    "            'Patient, identify, identification, treatment data'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'process_id': '8-3', \n",
    "        'keywords': [\n",
    "            'fail, lack', \n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'process_id': '8-4', \n",
    "        'keywords': [\n",
    "            'Wrong, incorrect, not applied, lack, different, no use', \n",
    "            'Immobilization device, immobilization aids, treatment accessories'\n",
    "        ]\n",
    "    }, \n",
    "    {\n",
    "        'process_id': '8-5', \n",
    "        'keywords': [\n",
    "            'Wrong match, mismatch, misinterpretation'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'process_id': '8-8', \n",
    "        'keywords': [\n",
    "            'Collision, monitor',\n",
    "        ]\n",
    "    },   \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d24991",
   "metadata": {},
   "source": [
    "### Change word form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff70021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_word_form(keywords):\n",
    "    new_keywords = [keyword for keyword in keywords]\n",
    "    for keyword in keywords:\n",
    "        if ' ' in keyword:\n",
    "            new_keywords.append(p.plural(keyword))\n",
    "        else:\n",
    "            for value_set in get_word_forms(keyword).values():\n",
    "                if len(value_set) != 0:\n",
    "                    new_keywords.extend(value_set)\n",
    "    return list(set(new_keywords))\n",
    "\n",
    "def keywords_to_list(keywords_list):\n",
    "    for step_keywords in keywords_list:\n",
    "        new_keywords = []\n",
    "        for group in step_keywords['keywords']:\n",
    "            keywords = [elem.strip() for elem in group.lower().split(', ')]\n",
    "            keywords = change_word_form(keywords)\n",
    "            new_keywords.append(keywords)\n",
    "        \n",
    "        step_keywords['keywords'] = new_keywords\n",
    "        \n",
    "keywords_to_list(keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345bc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_duplicates_dict = {}\n",
    "\n",
    "def find_duplicates_via_keywords(df_group_dict, keywords_list):\n",
    "    for fm_keywords in keywords_list:\n",
    "        for process_id, df in df_group_dict.items():\n",
    "            if fm_keywords['process_id'] == process_id:\n",
    "                duplicates = []\n",
    "                for index, row in df.iterrows():\n",
    "                    fm_list = row['F_m'].strip().lower().split( )\n",
    "                    count = 0\n",
    "                    for group in fm_keywords['keywords']: \n",
    "                        for word in fm_list:\n",
    "                            # remove apostrophe\n",
    "                            word = word.replace('’s', '')\n",
    "                            if word in group:\n",
    "                                count += 1\n",
    "                                break\n",
    "                    if count == len(fm_keywords['keywords']):\n",
    "                        duplicates.append(row['ID'])\n",
    "                keywords_duplicates_dict[process_id] = duplicates\n",
    "                                \n",
    "find_duplicates_via_keywords(df_group_dict, keywords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90019f5",
   "metadata": {},
   "source": [
    "## Find duplicates based on separator (i.e., :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a019d3d",
   "metadata": {},
   "source": [
    "### Filter dataframes only from source 05AR03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "950b8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = df_excel[(df_excel['Source'] == '05AR03')]\n",
    "# df_source = df_excel[(df_excel['Source'] == '05AR03') & (df_excel['subprocess_id'].isin(['6', '8']))]\n",
    "# df_source = df_excel[(df_excel['Source'] == '05AR03') & (df_excel['process_id'] == '8-4')]\n",
    "df_group_source_dict = {k: df for k, df in df_source.groupby('process_id')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbd87ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_duplicates_dict = {}\n",
    "\n",
    "def find_duplicates_via_colon(df_group_source_dict):\n",
    "    temp = {}\n",
    "    for process_id, df in df_group_source_dict.items():\n",
    "        for index, row in df.iterrows():\n",
    "            if ':' in row['F_m']:\n",
    "                general_fm = row['F_m'].split(':')[0].strip().lower()\n",
    "                if process_id not in temp:\n",
    "                    temp[process_id] = {general_fm: [row['ID']]}\n",
    "                else:\n",
    "                    if general_fm not in temp[process_id].keys():\n",
    "                        temp[process_id][general_fm] = [row['ID']]\n",
    "                    else:\n",
    "                        temp[process_id][general_fm].append(row['ID'])\n",
    "                        \n",
    "    for process_id, fm_obj in temp.items():\n",
    "        source_duplicates_dict[process_id] = [id_list for general_fm, id_list in fm_obj.items()]\n",
    "\n",
    "find_duplicates_via_colon(df_group_source_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64e952",
   "metadata": {},
   "source": [
    "## Find duplicates using the exact same wording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c716d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_same = df_excel[df_excel['F_m_count'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a5c2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_same_duplicates_dict = {}\n",
    "\n",
    "def find_duplicates_via_same(df):\n",
    "    temp = {}\n",
    "    for index, row in df.iterrows():\n",
    "        if row['process_id'] not in temp:\n",
    "            temp[row['process_id']] = {row['F_m']: [row['ID']]}\n",
    "        else:\n",
    "            if row['F_m'] not in temp[row['process_id']].keys():\n",
    "                temp[row['process_id']][row['F_m']] = [row['ID']]\n",
    "            else:\n",
    "                temp[row['process_id']][row['F_m']].append(row['ID'])\n",
    "                \n",
    "    for process_id, fm_obj in temp.items():\n",
    "        exact_same_duplicates_dict[process_id] = [id_list for general_fm, id_list in fm_obj.items()]\n",
    "\n",
    "find_duplicates_via_same(df_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca7063",
   "metadata": {},
   "source": [
    "## Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d95ebc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df_excel.drop(['subprocess_id', 'step_id', 'process_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90d31eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_IDs = []\n",
    "\n",
    "def export_to_separate_sheet(ditc_list, output_path):\n",
    "    with pd.ExcelWriter(output_path) as writer: \n",
    "        for duplicates_dict, filename in ditc_list:\n",
    "            if filename == 'keywords_':\n",
    "                duplicates = []\n",
    "                for process_id, ids in duplicates_dict.items():\n",
    "                    duplicates.extend(ids)\n",
    "                    df_drop.loc[df_drop['ID'].isin(ids)].to_excel(writer, filename + process_id, index=False)\n",
    "                duplicate_IDs.append(duplicates)\n",
    "            else:\n",
    "                duplicates = []\n",
    "                for process_id, id_list in duplicates_dict.items():\n",
    "                    new_ids = []\n",
    "                    for ids in id_list:\n",
    "                        if len(ids) > 1:\n",
    "                            duplicates.extend(ids)\n",
    "                            new_ids.extend(ids)\n",
    "                    df_drop.loc[df_drop['ID'].isin(new_ids)].to_excel(writer, filename + process_id, index=False)\n",
    "                duplicate_IDs.append(duplicates)\n",
    "            \n",
    "export_to_separate_sheet([(keywords_duplicates_dict, 'keywords_'), \n",
    "                 (source_duplicates_dict, '05AR03_'), \n",
    "                 (exact_same_duplicates_dict, 'same_')], output_separate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dd3caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_one_sheet(ditc_list, output_path):\n",
    "    with pd.ExcelWriter(output_path) as writer: \n",
    "        for duplicates_dict, filename in ditc_list:\n",
    "            id_collection = []\n",
    "            if filename == 'keywords':\n",
    "                for process_id, ids in duplicates_dict.items():\n",
    "                    id_collection.extend(ids)\n",
    "            else:\n",
    "                for process_id, id_list in duplicates_dict.items():\n",
    "                    for ids in id_list:\n",
    "                        if len(ids) > 1:\n",
    "                            id_collection.extend(ids)\n",
    "            df_drop.loc[df_drop['ID'].isin(id_collection)].to_excel(writer, filename, index=False)\n",
    "            \n",
    "export_to_one_sheet([(keywords_duplicates_dict, 'keywords'), \n",
    "                 (source_duplicates_dict, '05AR03'), \n",
    "                 (exact_same_duplicates_dict, 'same')], output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b977b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = []\n",
    "\n",
    "def export_without_duplicates(id_list, output_path, sheet_name):\n",
    "    unique_ids = list(set([item for sublist in duplicate_IDs for item in sublist]))\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl', mode='a') as writer: \n",
    "         df_drop.loc[df_drop['ID'].isin(unique_ids)].sort_values(by=['Subprocess', 'Step'], ascending=[True, True]).to_excel(writer, sheet_name, index=False) \n",
    "            \n",
    "export_without_duplicates(duplicate_IDs, output_path, 'no_duplicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfa72e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_duplicates(ids):\n",
    "    df = df_excel.loc[df_excel['ID'].isin(ids)]\n",
    "    df_dict = {k: df for k, df in df.groupby('process_id')}\n",
    "    count_dict = {k: len(df) for k, df in df.groupby('process_id')}\n",
    "    return df_dict, count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c28510ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'6-4': 15, '6-5': 2, '8-1': 7, '8-3': 4, '8-5': 2, '8-8': 7},\n",
       " {'4-11': 2,\n",
       "  '4-8': 4,\n",
       "  '5-1': 5,\n",
       "  '6-4': 6,\n",
       "  '6-5': 2,\n",
       "  '6-6': 39,\n",
       "  '6-7': 6,\n",
       "  '6-8': 6,\n",
       "  '6-9': 32,\n",
       "  '8-2': 5,\n",
       "  '8-4': 9,\n",
       "  '8-5': 2,\n",
       "  '8-8': 12},\n",
       " {'10-1': 2, '6-6': 18, '6-9': 27, '8-2': 3, '8-4': 3, '8-6': 4}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_dict_list = []\n",
    "for ids in duplicate_IDs:\n",
    "    df_dict, count_dict = count_duplicates(ids)\n",
    "    id_dict_list.append(count_dict)\n",
    "id_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e4ba4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10-1': 2,\n",
       " '4-11': 2,\n",
       " '4-8': 4,\n",
       " '5-1': 5,\n",
       " '6-4': 17,\n",
       " '6-5': 4,\n",
       " '6-6': 39,\n",
       " '6-7': 6,\n",
       " '6-8': 6,\n",
       " '6-9': 32,\n",
       " '8-1': 7,\n",
       " '8-2': 5,\n",
       " '8-3': 4,\n",
       " '8-4': 9,\n",
       " '8-5': 3,\n",
       " '8-6': 4,\n",
       " '8-8': 17}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ids = list(set([item for sublist in duplicate_IDs for item in sublist]))\n",
    "df_dict, count_dict = count_duplicates(unique_ids)\n",
    "count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17fc629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(  +  “  –  #  >  ,  ®  ?  \\n  °  ”  ≤  <  *  -  ;  )  &  .  :  /  ’'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = []\n",
    "for index, row in df_excel.iterrows():\n",
    "    fm = row['F_m'].replace(' ', '')\n",
    "    for c in fm:\n",
    "        if not c.isalnum():\n",
    "            characters.append(c)\n",
    "\n",
    "\"  \".join(list(set(characters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Missed patient’s photo'.replace(' ', '')\n",
    "# for c in test:\n",
    "#     if not c.isalnum():\n",
    "#         characters.append(c)\n",
    "characters = [c for c in test if not c.isalnum()]\n",
    "\n",
    "list(set(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b95291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:isart]",
   "language": "python",
   "name": "conda-env-isart-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
